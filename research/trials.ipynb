{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\dil_copies\\\\Intern_Daily_Code_Files\\\\End-to-End-Medical-Chatbot-Project-Implementation\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\dil_copies\\\\Intern_Daily_Code_Files\\\\End-to-End-Medical-Chatbot-Project-Implementation'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract Data from the pdf file\n",
    "def load_pdf_file(data):\n",
    "    loader = DirectoryLoader(data,glob=\"*.pdf\",\n",
    "                             loader_cls=PyPDFLoader)\n",
    "    documents = loader.load()\n",
    "    return documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error loading file Data\\Medical.pdf\n"
     ]
    },
    {
     "ename": "PdfReadError",
     "evalue": "Unexpected end of stream",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPdfReadError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m extracted_data = \u001b[43mload_pdf_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mData/\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m extracted_data\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mload_pdf_file\u001b[39m\u001b[34m(data)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_pdf_file\u001b[39m(data):\n\u001b[32m      3\u001b[39m     loader = DirectoryLoader(data,glob=\u001b[33m\"\u001b[39m\u001b[33m*.pdf\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      4\u001b[39m                              loader_cls=PyPDFLoader)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     documents = \u001b[43mloader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m documents\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\dil_copies\\Intern_Daily_Code_Files\\End-to-End-Medical-Chatbot-Project-Implementation\\medi\\Lib\\site-packages\\langchain_community\\document_loaders\\directory.py:117\u001b[39m, in \u001b[36mDirectoryLoader.load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> List[Document]:\n\u001b[32m    116\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Load documents.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlazy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\dil_copies\\Intern_Daily_Code_Files\\End-to-End-Medical-Chatbot-Project-Implementation\\medi\\Lib\\site-packages\\langchain_community\\document_loaders\\directory.py:195\u001b[39m, in \u001b[36mDirectoryLoader.lazy_load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    193\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    194\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m items:\n\u001b[32m--> \u001b[39m\u001b[32m195\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lazy_load_file(i, p, pbar)\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pbar:\n\u001b[32m    198\u001b[39m     pbar.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\dil_copies\\Intern_Daily_Code_Files\\End-to-End-Medical-Chatbot-Project-Implementation\\medi\\Lib\\site-packages\\langchain_community\\document_loaders\\directory.py:233\u001b[39m, in \u001b[36mDirectoryLoader._lazy_load_file\u001b[39m\u001b[34m(self, item, path, pbar)\u001b[39m\n\u001b[32m    231\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    232\u001b[39m         logger.error(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError loading file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(item)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m233\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m pbar:\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\dil_copies\\Intern_Daily_Code_Files\\End-to-End-Medical-Chatbot-Project-Implementation\\medi\\Lib\\site-packages\\langchain_community\\document_loaders\\directory.py:223\u001b[39m, in \u001b[36mDirectoryLoader._lazy_load_file\u001b[39m\u001b[34m(self, item, path, pbar)\u001b[39m\n\u001b[32m    221\u001b[39m loader = \u001b[38;5;28mself\u001b[39m.loader_cls(\u001b[38;5;28mstr\u001b[39m(item), **\u001b[38;5;28mself\u001b[39m.loader_kwargs)\n\u001b[32m    222\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m223\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubdoc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlazy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubdoc\u001b[49m\n\u001b[32m    225\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\dil_copies\\Intern_Daily_Code_Files\\End-to-End-Medical-Chatbot-Project-Implementation\\medi\\Lib\\site-packages\\langchain_community\\document_loaders\\pdf.py:307\u001b[39m, in \u001b[36mPyPDFLoader.lazy_load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    305\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    306\u001b[39m     blob = Blob.from_path(\u001b[38;5;28mself\u001b[39m.file_path)  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m307\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.parser.lazy_parse(blob)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\dil_copies\\Intern_Daily_Code_Files\\End-to-End-Medical-Chatbot-Project-Implementation\\medi\\Lib\\site-packages\\langchain_community\\document_loaders\\parsers\\pdf.py:396\u001b[39m, in \u001b[36mPyPDFParser.lazy_parse\u001b[39m\u001b[34m(self, blob)\u001b[39m\n\u001b[32m    394\u001b[39m single_texts = []\n\u001b[32m    395\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m page_number, page \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(pdf_reader.pages):\n\u001b[32m--> \u001b[39m\u001b[32m396\u001b[39m     text_from_page = \u001b[43m_extract_text_from_page\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    397\u001b[39m     images_from_page = \u001b[38;5;28mself\u001b[39m.extract_images_from_page(page)\n\u001b[32m    398\u001b[39m     all_text = _merge_text_and_extras(\n\u001b[32m    399\u001b[39m         [images_from_page], text_from_page\n\u001b[32m    400\u001b[39m     ).strip()\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\dil_copies\\Intern_Daily_Code_Files\\End-to-End-Medical-Chatbot-Project-Implementation\\medi\\Lib\\site-packages\\langchain_community\\document_loaders\\parsers\\pdf.py:378\u001b[39m, in \u001b[36mPyPDFParser.lazy_parse.<locals>._extract_text_from_page\u001b[39m\u001b[34m(page)\u001b[39m\n\u001b[32m    376\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m page.extract_text()\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mextract_text\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextraction_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mextraction_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mextraction_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\dil_copies\\Intern_Daily_Code_Files\\End-to-End-Medical-Chatbot-Project-Implementation\\medi\\Lib\\site-packages\\pypdf\\_page.py:2378\u001b[39m, in \u001b[36mPageObject.extract_text\u001b[39m\u001b[34m(self, orientations, space_width, visitor_operand_before, visitor_operand_after, visitor_text, extraction_mode, *args, **kwargs)\u001b[39m\n\u001b[32m   2375\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(orientations, \u001b[38;5;28mint\u001b[39m):\n\u001b[32m   2376\u001b[39m     orientations = (orientations,)\n\u001b[32m-> \u001b[39m\u001b[32m2378\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_extract_text\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2379\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2380\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2381\u001b[39m \u001b[43m    \u001b[49m\u001b[43morientations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2382\u001b[39m \u001b[43m    \u001b[49m\u001b[43mspace_width\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2383\u001b[39m \u001b[43m    \u001b[49m\u001b[43mPG\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCONTENTS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2384\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvisitor_operand_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2385\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvisitor_operand_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2386\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvisitor_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2387\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\dil_copies\\Intern_Daily_Code_Files\\End-to-End-Medical-Chatbot-Project-Implementation\\medi\\Lib\\site-packages\\pypdf\\_page.py:2073\u001b[39m, in \u001b[36mPageObject._extract_text\u001b[39m\u001b[34m(self, obj, pdf, orientations, space_width, content_key, visitor_operand_before, visitor_operand_after, visitor_text)\u001b[39m\n\u001b[32m   2070\u001b[39m         \u001b[38;5;28;01mexcept\u001b[39;00m OrientationNotFoundError:\n\u001b[32m   2071\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2073\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m operands, operator \u001b[38;5;129;01min\u001b[39;00m \u001b[43mcontent\u001b[49m\u001b[43m.\u001b[49m\u001b[43moperations\u001b[49m:\n\u001b[32m   2074\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m visitor_operand_before \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2075\u001b[39m         visitor_operand_before(operator, operands, cm_matrix, tm_matrix)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\dil_copies\\Intern_Daily_Code_Files\\End-to-End-Medical-Chatbot-Project-Implementation\\medi\\Lib\\site-packages\\pypdf\\generic\\_data_structures.py:1432\u001b[39m, in \u001b[36mContentStream.operations\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1429\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m   1430\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moperations\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> List[Tuple[Any, \u001b[38;5;28mbytes\u001b[39m]]:\n\u001b[32m   1431\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._operations \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._data:\n\u001b[32m-> \u001b[39m\u001b[32m1432\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parse_content_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBytesIO\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1433\u001b[39m         \u001b[38;5;28mself\u001b[39m._data = \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1434\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._operations\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\dil_copies\\Intern_Daily_Code_Files\\End-to-End-Medical-Chatbot-Project-Implementation\\medi\\Lib\\site-packages\\pypdf\\generic\\_data_structures.py:1311\u001b[39m, in \u001b[36mContentStream._parse_content_stream\u001b[39m\u001b[34m(self, stream)\u001b[39m\n\u001b[32m   1307\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m operator == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBI\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1308\u001b[39m     \u001b[38;5;66;03m# begin inline image - a completely different parsing\u001b[39;00m\n\u001b[32m   1309\u001b[39m     \u001b[38;5;66;03m# mechanism is required, of course... thanks buddy...\u001b[39;00m\n\u001b[32m   1310\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m operands == []\n\u001b[32m-> \u001b[39m\u001b[32m1311\u001b[39m     ii = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_inline_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1312\u001b[39m     \u001b[38;5;28mself\u001b[39m._operations.append((ii, \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mINLINE IMAGE\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m   1313\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\dil_copies\\Intern_Daily_Code_Files\\End-to-End-Medical-Chatbot-Project-Implementation\\medi\\Lib\\site-packages\\pypdf\\generic\\_data_structures.py:1383\u001b[39m, in \u001b[36mContentStream._read_inline_image\u001b[39m\u001b[34m(self, stream)\u001b[39m\n\u001b[32m   1381\u001b[39m     stream.seek(-\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m)\n\u001b[32m   1382\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1383\u001b[39m     data = \u001b[43mextract_inline_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1385\u001b[39m ei = stream.read(\u001b[32m3\u001b[39m)\n\u001b[32m   1386\u001b[39m stream.seek(-\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\dil_copies\\Intern_Daily_Code_Files\\End-to-End-Medical-Chatbot-Project-Implementation\\medi\\Lib\\site-packages\\pypdf\\generic\\_image_inline.py:201\u001b[39m, in \u001b[36mextract_inline_default\u001b[39m\u001b[34m(stream)\u001b[39m\n\u001b[32m    199\u001b[39m data_buffered = stream.read(BUFFER_SIZE)\n\u001b[32m    200\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data_buffered:\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m PdfReadError(\u001b[33m\"\u001b[39m\u001b[33mUnexpected end of stream\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    202\u001b[39m pos_ei = data_buffered.find(\n\u001b[32m    203\u001b[39m     \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mE\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    204\u001b[39m )  \u001b[38;5;66;03m# we can not look straight for \"EI\" because it may not have been loaded in the buffer\u001b[39;00m\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pos_ei == -\u001b[32m1\u001b[39m:\n",
      "\u001b[31mPdfReadError\u001b[39m: Unexpected end of stream"
     ]
    }
   ],
   "source": [
    "extracted_data = load_pdf_file(data='Data/')\n",
    "extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the dara innto text chunks\n",
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_over_lap=20)\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'extracted_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m text_chunks = text_split(\u001b[43mextracted_data\u001b[49m)\n\u001b[32m      2\u001b[39m text_chunks\n",
      "\u001b[31mNameError\u001b[39m: name 'extracted_data' is not defined"
     ]
    }
   ],
   "source": [
    "text_chunks = text_split(extracted_data)\n",
    "text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "#download the embedding from hugging face\n",
    "def download_hugging_face_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "    return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_16408\\3772398354.py:5: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
      "e:\\dil_copies\\Intern_Daily_Code_Files\\End-to-End-Medical-Chatbot-Project-Implementation\\medi\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Could not import sentence_transformers python package. Please install it with `pip install sentence-transformers`.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\dil_copies\\Intern_Daily_Code_Files\\End-to-End-Medical-Chatbot-Project-Implementation\\medi\\Lib\\site-packages\\langchain_community\\embeddings\\huggingface.py:84\u001b[39m, in \u001b[36mHuggingFaceEmbeddings.__init__\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\dil_copies\\Intern_Daily_Code_Files\\End-to-End-Medical-Chatbot-Project-Implementation\\medi\\Lib\\site-packages\\sentence_transformers\\__init__.py:3\u001b[39m\n\u001b[32m      2\u001b[39m __MODEL_HUB_ORGANIZATION__ = \u001b[33m'\u001b[39m\u001b[33msentence-transformers\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentencesDataset, ParallelSentencesDataset\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mLoggingHandler\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LoggingHandler\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\dil_copies\\Intern_Daily_Code_Files\\End-to-End-Medical-Chatbot-Project-Implementation\\medi\\Lib\\site-packages\\sentence_transformers\\datasets\\__init__.py:3\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mNoDuplicatesDataLoader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NoDuplicatesDataLoader\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mParallelSentencesDataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ParallelSentencesDataset\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mSentencesDataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentencesDataset\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\dil_copies\\Intern_Daily_Code_Files\\End-to-End-Medical-Chatbot-Project-Implementation\\medi\\Lib\\site-packages\\sentence_transformers\\datasets\\ParallelSentencesDataset.py:4\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgzip\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mreaders\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m InputExample\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\dil_copies\\Intern_Daily_Code_Files\\End-to-End-Medical-Chatbot-Project-Implementation\\medi\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:12\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhuggingface_hub\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HfApi, HfFolder, Repository, hf_hub_url, cached_download\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'cached_download' from 'huggingface_hub' (e:\\dil_copies\\Intern_Daily_Code_Files\\End-to-End-Medical-Chatbot-Project-Implementation\\medi\\Lib\\site-packages\\huggingface_hub\\__init__.py)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m embeddings = \u001b[43mdownload_hugging_face_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mdownload_hugging_face_embeddings\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdownload_hugging_face_embeddings\u001b[39m():\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     embeddings = \u001b[43mHuggingFaceEmbeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msentence-transformers/all-MiniLM-L6-v2\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m embeddings\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\dil_copies\\Intern_Daily_Code_Files\\End-to-End-Medical-Chatbot-Project-Implementation\\medi\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:214\u001b[39m, in \u001b[36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m     warned = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    213\u001b[39m     emit_warning()\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\dil_copies\\Intern_Daily_Code_Files\\End-to-End-Medical-Chatbot-Project-Implementation\\medi\\Lib\\site-packages\\langchain_community\\embeddings\\huggingface.py:87\u001b[39m, in \u001b[36mHuggingFaceEmbeddings.__init__\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m     84\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m     88\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCould not import sentence_transformers python package. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     89\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease install it with `pip install sentence-transformers`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     90\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m     92\u001b[39m \u001b[38;5;28mself\u001b[39m.client = sentence_transformers.SentenceTransformer(\n\u001b[32m     93\u001b[39m     \u001b[38;5;28mself\u001b[39m.model_name, cache_folder=\u001b[38;5;28mself\u001b[39m.cache_folder, **\u001b[38;5;28mself\u001b[39m.model_kwargs\n\u001b[32m     94\u001b[39m )\n",
      "\u001b[31mImportError\u001b[39m: Could not import sentence_transformers python package. Please install it with `pip install sentence-transformers`."
     ]
    }
   ],
   "source": [
    "embeddings = download_hugging_face_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m query_result = \u001b[43membeddings\u001b[49m.embed_query(\u001b[33m\"\u001b[39m\u001b[33mHello world\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mlength\u001b[39m\u001b[33m\"\u001b[39m,\u001b[38;5;28mlen\u001b[39m(query_result))\n",
      "\u001b[31mNameError\u001b[39m: name 'embeddings' is not defined"
     ]
    }
   ],
   "source": [
    "query_result = embeddings.embed_query(\"Hello world\")\n",
    "print(\"length\",len(query_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = os.environ.get('PINECONE_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
